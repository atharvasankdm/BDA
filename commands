Open a terminal window to the current working directory.
# /home/training
# 1. Print the Hadoop version
hadoop version
# 2. List the contents of the root directory in HDFS
#
hadoop fs
ls /
# 3. Report the amount of space used and
# avai
lable on currently mounted filesystem
#
hadoop fs
df hdfs:/
# 4. Count the number of directories,files and bytes under
# the paths that match the specified file pattern
#
hadoop fs
count hdfs:/
# 5. Run a DFS filesystem checking utility
#
hadoop fsck
# 6. Run a cluster balancing utility
#
hadoop balancer
# 7. Create a new directory named "hadoop" below the
# /user/training directory in HDFS. Since you're
# currently logged in with the "training" user ID,
# /user/training is your home directory in
HDFS.
#
hadoop fs
mkdir /user/training/hadoop
# 8. Add a sample text file from the local directory
# named "data" to the new directory you created in HDFS
# during the previous step.
#
hadoop fs
put data/sample.txt /user/training/hadoop
# 9. List the c
# 9. List the contents of this new directory in HDFS.ontents of this new directory in HDFS.
#
#
hadoop fs
hadoop fs --ls /user/training/hadoopls /user/training/hadoop
# 10. Add the entire local directory called "retail" to the
# 10. Add the entire local directory called "retail" to the
# /user/training directory in HDFS.
# /user/training directory in HDFS.
#
#
hadoop fs
hadoop fs --put data/retail /user/training/hadoopput data/retail /user/training/hadoop
# 11. Since /user/training is
# 11. Since /user/training is your home directory in HDFS,your home directory in HDFS,
# any command that does not have an absolute path is
# any command that does not have an absolute path is
# interpreted as relative to that directory. The next
# interpreted as relative to that directory. The next
# command will therefore list your home directory, and
# command will therefore list your home directory, and
# should show the items you've just added there.
# should show the items you've just added there.
#
#
hadoop fs
hadoop fs --lsls
# 12. See how much space this directory occupies in HDFS.
# 12. See how much space this directory occupies in HDFS.
#
#
hadoop fs
hadoop fs --du du --s s --h hadoop/retailh hadoop/retail
# 13. Delete a file 'customers' from the "retail" directory.
# 13. Delete a file 'customers' from the "retail" directory.
#
#
hadoop fs
hadoop fs --rm hadoop/retail/customersrm hadoop/retail/customers
# 14. Ensure this file is no longer in HDFS.
# 14. Ensure this file is no longer in HDFS.
#
#
hadoop fs
hadoop fs --ls hadoop/retail/customersls hadoop/retail/customers
# 15. Delete all files from the "retail" directory using a wildcard.
# 15. Delete all files from the "retail" directory using a wildcard.
#
#
hadoop fs
hadoop fs --rm hadoop/retail/*rm hadoop/retail/*
# 16. To empty the trash
# 16. To empty the trash
#
#
hadoop fs
hadoop fs --expungeexpunge
# 17. Finally, remove the entire retail directory and all
# 17. Finally, remove the entire retail directory and all
# of its contents in
# of its contents in HDFS.HDFS.
#
#
hadoop fs
hadoop fs --rm rm --r hadoop/retailr hadoop/retail
# 18. List the hadoop directory again
# 18. List the hadoop directory again
#
#
hadoop fs
hadoop fs --ls hadoopls hadoop
# 19. Add the purchases.txt file from the local directory
# 19. Add the purchases.txt file from the local directory
# named "/home/training/" to the hadoop directory you created in HDFS
# named "/home/training/" to the hadoop directory you created in HDFS
#
#
hadoop fs
hadoop fs --copyFromLocalcopyFromLocal /home/training/purchases.txt hadoop//home/training/purchases.txt hadoop/
# 20. To view the contents of your text file purchases.txt
# 20. To view the contents of your text file purchases.txt
# which is present in your hadoop directory.
# which is present in your hadoop directory.
#
#
hadoop fs
hadoop fs --cat hadoop/purchases.txtcat hadoop/purchases.txt
# 21. Add the purchases.txt file from "hadoop" directory which is present
# 21. Add the purchases.txt file from "hadoop" directory which is present in HDFS directoryin HDFS directory
# to the directory "data" which is present in your local directory
# to the directory "data" which is present in your local directory
#
#
hadoop fs
hadoop fs --copyToLocal hadoop/purchases.txt /home/training/datacopyToLocal hadoop/purchases.txt /home/training/data
# 22. cp is used to copy files between directories present in HDFS
# 22. cp is used to copy files between directories present in HDFS
#
#
hadoop fs
hadoop fs --cp /user/training/*.txt cp /user/training/*.txt /user/training/hadoop/user/training/hadoop
# 23. '
# 23. '--get' command can be used alternaively to 'get' command can be used alternaively to '--copyToLocal' commandcopyToLocal' command
#
#
hadoop fs
hadoop fs --get hadoop/sample.txt /home/training/get hadoop/sample.txt /home/training/
# 24. Display last kilobyte of the file "purchases.txt" to stdout.
# 24. Display last kilobyte of the file "purchases.txt" to stdout.
#
#
hadoop fs
hadoop fs --tail hadoop/purchases.txttail hadoop/purchases.txt
#
# 25. Default file permissions are 666 in HDFS25. Default file permissions are 666 in HDFS
# Use '
# Use '--chmod' command to change permissions of a filechmod' command to change permissions of a file
#
#
hadoop fs
hadoop fs --ls hadoop/purchases.txtls hadoop/purchases.txt
sudo
sudo --u hdfs hadoop fs u hdfs hadoop fs --chmod 600 hadoop/purchases.txtchmod 600 hadoop/purchases.txt
# 26. Default names of owner and group are training,training
# 26. Default names of owner and group are training,training
#
# Use 'Use '--chown' to change owner name and group name simultaneouslychown' to change owner name and group name simultaneously
#
#
hadoop fs
hadoop fs --ls hadoop/purchases.txtls hadoop/purchases.txt
sudo
sudo --u hdfs hadoop fs u hdfs hadoop fs --chown root:root hadoop/purchases.txtchown root:root hadoop/purchases.txt
# 27. Default name of group is training
# 27. Default name of group is training
# Use '
# Use '--chgrp' command to change group namechgrp' command to change group name
#
#
hadoop
hadoop fs fs --ls hadoop/purchases.txtls hadoop/purchases.txt
sudo
sudo --u hdfs hadoop fs u hdfs hadoop fs --chgrp training hadoop/purchases.txtchgrp training hadoop/purchases.txt
# 28. Move a directory from one location to other
# 28. Move a directory from one location to other
#
#
hadoop fs
hadoop fs --mv hadoop apache_hadoopmv hadoop apache_hadoop
# 29. Default replication factor to a file is 3.
# 29. Default replication factor to a file is 3.
# Use '
# Use '--setrep' command to chasetrep' command to change replication factor of a filenge replication factor of a file
#
#
hadoop fs
hadoop fs --setrep setrep --w 2 apache_hadoop/sample.txtw 2 apache_hadoop/sample.txt
# 30. Copy a directory from one node in the cluster to another
# 30. Copy a directory from one node in the cluster to another
# Use '
# Use '--distcp' command to copy,distcp' command to copy,
#
# --overwrite option to overwrite in an existing filesoverwrite option to overwrite in an existing files
#
# --update command to supdate command to synchronize both directoriesynchronize both directories
#
#
hadoop fs
hadoop fs --distcp hdfs://namenodeA/apache_hadoop hdfs://namenodeB/hadoopdistcp hdfs://namenodeA/apache_hadoop hdfs://namenodeB/hadoop
# 31. Command to make the name node leave safe mode
# 31. Command to make the name node leave safe mode
#
#
hadoop fs
hadoop fs --expungeexpunge
sudo
sudo --u hdfs hdfs dfsadmin u hdfs hdfs dfsadmin --safemode leavesafemode leave
# 32. List all the hadoop file syst
# 32. List all the hadoop file system shell commandsem shell commands
#
#
hadoop fs
hadoop fs
# 33. Last but not least, always ask for help!
# 33. Last but not least, always ask for help!
#
#
hadoop fs
hadoop fs --helphelp
